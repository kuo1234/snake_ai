# æ”¹å‹•ç¸½çµ - Snake AI PPO ç‰ˆæœ¬

## å®Œæˆçš„å·¥ä½œ

### 1. âœ… ä¿®æ”¹è¨ˆåˆ†ç³»çµ±
- **æª”æ¡ˆ**: `snake_game.py`, `envs/snake_game.py`
- **æ”¹å‹•**: æ¯æ¬¡åƒåˆ°é£Ÿç‰©å¾ +10 åˆ†æ”¹ç‚º +1 åˆ†
- **æœ€é«˜åˆ†**: board_sizeÂ² - 1
  - 8x8: æœ€é«˜ 63 åˆ†
  - 10x10: æœ€é«˜ 99 åˆ†

### 2. âœ… å‰µå»º Gymnasium ç’°å¢ƒåŒ…è£
- **æª”æ¡ˆ**: `envs/gym_snake_env.py`
- **åŠŸèƒ½**: 
  - å¯¦ç¾å®Œæ•´çš„ Gym Env ä»‹é¢
  - 12 ç¶­è§€å¯Ÿç©ºé–“ï¼ˆå±éšªæª¢æ¸¬ + é£Ÿç‰©æ–¹å‘ + ç•¶å‰æ–¹å‘ï¼‰
  - 4 å€‹é›¢æ•£å‹•ä½œï¼ˆä¸Šä¸‹å·¦å³ï¼‰
  - çå‹µå¡‘å½¢ï¼ˆreward shapingï¼‰
  - æ”¯æ´ stable_baselines3

### 3. âœ… å‰µå»º PPO è¨“ç·´è…³æœ¬
- **æª”æ¡ˆ**: `snake_ai_ppo.py`
- **æ–¹æ³•**: PPO (Proximal Policy Optimization)
- **æ¡†æ¶**: stable_baselines3 + PyTorch
- **åŠŸèƒ½**:
  - è¨“ç·´æ¨¡å¼ï¼šå¤šé€²ç¨‹ä¸¦è¡Œè¨“ç·´
  - è©•ä¼°æ¨¡å¼ï¼šå¿«é€Ÿæ€§èƒ½æ¸¬è©¦
  - æ¼”ç¤ºæ¨¡å¼ï¼šåœ–å½¢ç•Œé¢è§€çœ‹ AI
  - è‡ªå‹•ä¿å­˜æœ€ä½³æ¨¡å‹å’Œæª¢æŸ¥é»
  - Tensorboard æ—¥èªŒè¨˜éŒ„

### 4. âœ… æ›´æ–°ä¾è³´
- **æª”æ¡ˆ**: `requirements.txt`
- **æ–°å¢ä¾è³´**:
  - gymnasium==0.29.1
  - torch>=2.0.0
  - stable-baselines3>=2.0.0
  - tensorboard>=2.14.0

### 5. âœ… æ–‡æª”
- **PPO_README.md**: è©³ç´°çš„ PPO ä½¿ç”¨æŒ‡å—
- **README.md**: æ›´æ–°ä¸»æ–‡æª”ï¼Œèªªæ˜æ–°èˆŠå…©ç¨® AI æ–¹æ³•

## ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿé–‹å§‹

```powershell
# 1. å®‰è£ä¾è³´
pip install -r requirements.txt

# 2. å¿«é€Ÿè¨“ç·´ï¼ˆ10è¬æ­¥ï¼Œç´„5-10åˆ†é˜ï¼‰
python snake_ai_ppo.py --mode train --timesteps 100000 --board-size 8

# 3. è§€çœ‹ AI ç©éŠæˆ²
python snake_ai_ppo.py --mode demo --model-path models/ppo_snake/ppo_snake_final
```

### æ¨è–¦è¨“ç·´æµç¨‹

1. **åˆæ¬¡æ¸¬è©¦** (10è¬æ­¥)ï¼š
   ```powershell
   python snake_ai_ppo.py --mode train --timesteps 100000 --board-size 6
   ```

2. **æ¨™æº–è¨“ç·´** (50è¬æ­¥)ï¼š
   ```powershell
   python snake_ai_ppo.py --mode train --timesteps 500000 --board-size 8
   ```

3. **é•·æ™‚é–“è¨“ç·´** (100è¬æ­¥+)ï¼š
   ```powershell
   python snake_ai_ppo.py --mode train --timesteps 1000000 --board-size 10
   ```

## æª”æ¡ˆçµæ§‹

```
snake_ai/
â”œâ”€â”€ envs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ snake_game.py          # éŠæˆ²æ ¸å¿ƒé‚è¼¯ï¼ˆå·²ä¿®æ”¹è¨ˆåˆ†ï¼‰
â”‚   â”œâ”€â”€ gym_snake_env.py       # Gymnasium ç’°å¢ƒåŒ…è£ï¼ˆæ–°å¢ï¼‰
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ snake_ai_ppo.py            # PPO è¨“ç·´è…³æœ¬ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ snake_ai.py                # Q-learning æ–¹æ³•ï¼ˆåŸæœ‰ï¼‰
â”œâ”€â”€ train.py                   # Q-learning è¨“ç·´ï¼ˆåŸæœ‰ï¼‰
â”œâ”€â”€ PPO_README.md              # PPO ä½¿ç”¨æŒ‡å—ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ README.md                  # ä¸»æ–‡æª”ï¼ˆå·²æ›´æ–°ï¼‰
â””â”€â”€ requirements.txt           # ä¾è³´æ¸…å–®ï¼ˆå·²æ›´æ–°ï¼‰
```

## PPO vs Q-learning æ¯”è¼ƒ

| ç‰¹æ€§ | PPO | Q-learning |
|-----|-----|-----------|
| ç®—æ³•é¡å‹ | Policy-based (ç­–ç•¥æ¢¯åº¦) | Value-based (å€¼å‡½æ•¸) |
| ç¥ç¶“ç¶²è·¯ | æ·±åº¦ç¥ç¶“ç¶²è·¯ | ç„¡ï¼ˆä½¿ç”¨ Q è¡¨ï¼‰ |
| è¨“ç·´é€Ÿåº¦ | å¿«ï¼ˆå¤šé€²ç¨‹ï¼‰ | æ…¢ï¼ˆå–®é€²ç¨‹ï¼‰ |
| æ“´å±•æ€§ | å¥½ï¼ˆé©åˆå¤§ç‹€æ…‹ç©ºé–“ï¼‰ | å·®ï¼ˆç‹€æ…‹çˆ†ç‚¸ï¼‰ |
| æ£‹ç›¤å¤§å° | 6-16+ | 6-10 |
| æ¡†æ¶ | stable_baselines3 + PyTorch | è‡ªå¯¦ç¾ |
| æ¨è–¦ä½¿ç”¨ | âœ… æ¨è–¦ | å­¸ç¿’ç”¨é€” |

## å¾ŒçºŒå„ªåŒ–æ–¹å‘

1. **èª¿æ•´è¶…åƒæ•¸**:
   - å­¸ç¿’ç‡ã€batch sizeã€n_steps ç­‰
   - ä½¿ç”¨ Optuna è‡ªå‹•èª¿åƒ

2. **æ”¹é€²è§€å¯Ÿç©ºé–“**:
   - å¢åŠ æ›´å¤šç‰¹å¾µï¼ˆè›‡èº«ä½ç½®ã€å¤šæ­¥å‰ç»ï¼‰
   - ä½¿ç”¨ CNN è™•ç†åœ–åƒè¼¸å…¥

3. **æ”¹é€²çå‹µå‡½æ•¸**:
   - æ›´ç´°ç·»çš„çå‹µå¡‘å½¢
   - æ·»åŠ ä¸­é–“ç›®æ¨™çå‹µ

4. **å˜—è©¦å…¶ä»–ç®—æ³•**:
   - A2C (åŒæ­¥ç‰ˆæœ¬çš„ A3C)
   - DQN (Deep Q-Network)
   - SAC (Soft Actor-Critic)

5. **é€²éšæŠ€è¡“**:
   - Curriculum Learningï¼ˆèª²ç¨‹å­¸ç¿’ï¼‰
   - Recurrent Policiesï¼ˆLSTM/GRUï¼‰
   - Self-playï¼ˆè‡ªæˆ‘å°å¼ˆï¼‰

## æ¸¬è©¦ç‹€æ…‹

âœ… æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å·²æ¸¬è©¦ä¸¦æ­£å¸¸é‹è¡Œï¼š
- Gymnasium ç’°å¢ƒå‰µå»ºå’Œé‹è¡Œ
- è§€å¯Ÿç©ºé–“æ­£ç¢ºï¼ˆ12 ç¶­ï¼‰
- å‹•ä½œç©ºé–“æ­£ç¢ºï¼ˆ4 å€‹å‹•ä½œï¼‰
- è¨ˆåˆ†ç³»çµ±æ­£ç¢ºï¼ˆ+1 åˆ†/é£Ÿç‰©ï¼‰
- PPO è…³æœ¬å¯å°å…¥ä¸¦åŸ·è¡Œ

## é–‹å§‹è¨“ç·´ï¼

ç¾åœ¨ä½ å¯ä»¥é–‹å§‹è¨“ç·´ä½ çš„ Snake AI äº†ï¼å»ºè­°å¾å°æ£‹ç›¤ï¼ˆ6x6 æˆ– 8x8ï¼‰å’Œè¼ƒå°‘çš„è¨“ç·´æ­¥æ•¸ï¼ˆ10è¬ï¼‰é–‹å§‹ï¼Œè§€å¯Ÿæ•ˆæœå¾Œå†å¢åŠ é›£åº¦ã€‚

ç¥è¨“ç·´é †åˆ©ï¼ğŸğŸ®ğŸ¤–
