"""
PPO V3: Curriculum Learningç‰ˆæœ¬
çµåˆ V2 çš„çå‹µå¡‘å½¢ + èª²ç¨‹å­¸ç¿’ï¼ˆå¾æ˜“åˆ°é›£ï¼‰

èª²ç¨‹è¨­è¨ˆï¼š
éšæ®µ 1: 6x6 å°æ£‹ç›¤ï¼ˆæ–°æ‰‹æ‘ï¼‰- å­¸ç¿’åŸºæœ¬ç”Ÿå­˜å’Œè¦“é£Ÿ
éšæ®µ 2: 8x8 æ¨™æº–æ£‹ç›¤ï¼ˆé€²éšç­ï¼‰- åœ¨ä¸­ç­‰ç©ºé–“ä¸­å„ªåŒ–ç­–ç•¥
éšæ®µ 3: 10x10 å›°é›£æ£‹ç›¤ï¼ˆæŒ‘æˆ°ç­ï¼‰- è™•ç†æ›´è¤‡é›œçš„ç©ºé–“è¦åŠƒ
éšæ®µ 4: 12x12 æ¥µé›£æ£‹ç›¤ï¼ˆå¤§å¸«ç­ï¼‰- æœ€çµ‚æŒ‘æˆ°

æ¯å€‹éšæ®µéƒ½æœƒï¼š
1. ç¹¼æ‰¿ä¸Šä¸€éšæ®µçš„æ¨¡å‹ï¼ˆTransfer Learningï¼‰
2. è¨­å®šç•¢æ¥­æ¨™æº–ï¼ˆå¹³å‡åˆ†æ•¸é”æ¨™ï¼‰
3. ä½¿ç”¨ V2 çš„å¾®è§€æ•™ç·´ï¼ˆçå‹µå¡‘å½¢ï¼‰

æ–°å¢ç‰¹æ€§ï¼š
- æ›´å¤§çš„ç¥ç¶“ç¶²è·¯ï¼ˆMLP [256, 256, 128] å–ä»£ [128, 128, 64]ï¼‰
- æ›´é•·çš„è¨“ç·´æ™‚é–“ï¼ˆæ¯éšæ®µå…è¨±æ›´å¤šæ¢ç´¢ï¼‰
- è‡ªå‹•éšæ®µåˆ‡æ›ï¼ˆé”æ¨™å¾Œè‡ªå‹•å‡ç´šï¼‰
- å®Œæ•´çš„è¨“ç·´è¿½è¹¤å’Œæ—¥èªŒ
"""

import os
import sys
import argparse
import time
import numpy as np
import torch
from typing import Optional, Dict, List
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv
from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.logger import configure

# å°å…¥ V2 ç’°å¢ƒ
from envs.gym_snake_env_v2 import GymSnakeEnvV2


class CurriculumStage:
    """èª²ç¨‹éšæ®µå®šç¾©"""
    def __init__(self, name: str, board_size: int, timesteps: int, 
                 graduation_score: float, description: str):
        self.name = name
        self.board_size = board_size
        self.timesteps = timesteps
        self.graduation_score = graduation_score
        self.description = description
        self.completed = False
        self.best_score = 0.0
        self.current_score = 0.0


class CurriculumManager:
    """èª²ç¨‹ç®¡ç†å™¨ - The Curriculum Coach"""
    
    def __init__(self, base_dir: str = "models/ppo_snake_v3_curriculum"):
        self.base_dir = base_dir
        os.makedirs(base_dir, exist_ok=True)
        
        # å®šç¾©èª²ç¨‹éšæ®µ
        self.stages = [
            CurriculumStage(
                name="Stage1_Novice",
                board_size=6,
                timesteps=300000,  # 30è¬æ­¥
                graduation_score=20.0,  # 6x6 æœ€é«˜35åˆ†ï¼Œè¦æ±‚20åˆ†ç•¢æ¥­
                description="æ–°æ‰‹æ‘ï¼š6x6å°æ£‹ç›¤ï¼Œå­¸ç¿’åŸºæœ¬ç”Ÿå­˜å’Œè¦“é£Ÿ"
            ),
            CurriculumStage(
                name="Stage2_Intermediate",
                board_size=8,
                timesteps=500000,  # 50è¬æ­¥
                graduation_score=35.0,  # 8x8 æœ€é«˜63åˆ†ï¼Œè¦æ±‚35åˆ†ç•¢æ¥­
                description="é€²éšç­ï¼š8x8æ¨™æº–æ£‹ç›¤ï¼Œå„ªåŒ–ä¸­ç­‰ç©ºé–“ç­–ç•¥"
            ),
            CurriculumStage(
                name="Stage3_Advanced",
                board_size=10,
                timesteps=800000,  # 80è¬æ­¥
                graduation_score=50.0,  # 10x10 æœ€é«˜99åˆ†ï¼Œè¦æ±‚50åˆ†ç•¢æ¥­
                description="æŒ‘æˆ°ç­ï¼š10x10å›°é›£æ£‹ç›¤ï¼Œè¤‡é›œç©ºé–“è¦åŠƒ"
            ),
            CurriculumStage(
                name="Stage4_Master",
                board_size=12,
                timesteps=1000000,  # 100è¬æ­¥
                graduation_score=70.0,  # 12x12 æœ€é«˜143åˆ†ï¼Œè¦æ±‚70åˆ†ç•¢æ¥­
                description="å¤§å¸«ç­ï¼š12x12æ¥µé›£æ£‹ç›¤ï¼Œçµ‚æ¥µæŒ‘æˆ°"
            )
        ]
        
        self.current_stage_idx = 0
        self.training_log = []
    
    @property
    def current_stage(self) -> CurriculumStage:
        """ç²å–ç•¶å‰éšæ®µ"""
        return self.stages[self.current_stage_idx]
    
    def check_graduation(self, mean_score: float) -> bool:
        """æª¢æŸ¥æ˜¯å¦é”åˆ°ç•¢æ¥­æ¨™æº–"""
        stage = self.current_stage
        stage.current_score = mean_score
        stage.best_score = max(stage.best_score, mean_score)
        
        if mean_score >= stage.graduation_score:
            stage.completed = True
            print(f"\nğŸ“ æ­å–œï¼{stage.name} ç•¢æ¥­äº†ï¼")
            print(f"   ç•¢æ¥­åˆ†æ•¸: {mean_score:.1f} (æ¨™æº–: {stage.graduation_score})")
            return True
        return False
    
    def advance_stage(self) -> bool:
        """é€²å…¥ä¸‹ä¸€éšæ®µ"""
        if self.current_stage_idx < len(self.stages) - 1:
            self.current_stage_idx += 1
            print(f"\nğŸ“ˆ å‡ç´šåˆ° {self.current_stage.name}!")
            print(f"   {self.current_stage.description}")
            return True
        else:
            print(f"\nğŸ† æ­å–œå®Œæˆæ‰€æœ‰èª²ç¨‹éšæ®µï¼")
            return False
    
    def get_model_path(self, stage: Optional[CurriculumStage] = None) -> str:
        """ç²å–æ¨¡å‹ä¿å­˜è·¯å¾‘"""
        if stage is None:
            stage = self.current_stage
        return os.path.join(self.base_dir, stage.name, "model")
    
    def get_best_model_path(self, stage: Optional[CurriculumStage] = None) -> str:
        """ç²å–æœ€ä½³æ¨¡å‹è·¯å¾‘"""
        if stage is None:
            stage = self.current_stage
        return os.path.join(self.base_dir, stage.name, "best_model")
    
    def save_progress(self):
        """ä¿å­˜è¨“ç·´é€²åº¦"""
        progress_file = os.path.join(self.base_dir, "curriculum_progress.txt")
        with open(progress_file, 'w', encoding='utf-8') as f:
            f.write("=== PPO V3 Curriculum Learning Progress ===\n\n")
            for i, stage in enumerate(self.stages):
                status = "âœ“ å·²å®Œæˆ" if stage.completed else "â—‹ é€²è¡Œä¸­" if i == self.current_stage_idx else "- æœªé–‹å§‹"
                f.write(f"{status} {stage.name} ({stage.board_size}x{stage.board_size})\n")
                f.write(f"   æè¿°: {stage.description}\n")
                f.write(f"   æœ€ä½³åˆ†æ•¸: {stage.best_score:.1f}\n")
                f.write(f"   ç•¢æ¥­æ¨™æº–: {stage.graduation_score}\n")
                f.write(f"   è¨“ç·´æ­¥æ•¸: {stage.timesteps}\n\n")
            
            f.write(f"\nç•¶å‰éšæ®µ: {self.current_stage.name}\n")


class CurriculumCallback(BaseCallback):
    """èª²ç¨‹å­¸ç¿’å›èª¿ - ç›£æ§è¨“ç·´é€²åº¦ä¸¦æ±ºå®šæ˜¯å¦ç•¢æ¥­"""
    
    def __init__(self, curriculum_manager: CurriculumManager, 
                 eval_freq: int = 10000, n_eval_episodes: int = 20,
                 verbose: int = 1):
        super().__init__(verbose)
        self.curriculum_manager = curriculum_manager
        self.eval_freq = eval_freq
        self.n_eval_episodes = n_eval_episodes
        self.eval_count = 0
    
    def _on_step(self) -> bool:
        # æ¯ eval_freq æ­¥è©•ä¼°ä¸€æ¬¡
        if self.n_calls % self.eval_freq == 0:
            self.eval_count += 1
            mean_score = self._evaluate_agent()
            
            stage = self.curriculum_manager.current_stage
            print(f"\n[è©•ä¼° #{self.eval_count}] {stage.name} - å¹³å‡åˆ†æ•¸: {mean_score:.1f} / {stage.graduation_score}")
            
            # æª¢æŸ¥æ˜¯å¦ç•¢æ¥­
            if self.curriculum_manager.check_graduation(mean_score):
                # ä¿å­˜ç•¢æ¥­æ¨¡å‹
                model_path = self.curriculum_manager.get_model_path()
                self.model.save(model_path)
                print(f"   âœ“ æ¨¡å‹å·²ä¿å­˜: {model_path}")
            
            # ä¿å­˜é€²åº¦
            self.curriculum_manager.save_progress()
        
        return True
    
    def _evaluate_agent(self) -> float:
        """è©•ä¼°ç•¶å‰æ™ºèƒ½é«”"""
        stage = self.curriculum_manager.current_stage
        env = GymSnakeEnvV2(board_size=stage.board_size, render_mode=None)
        
        scores = []
        for _ in range(self.n_eval_episodes):
            obs, info = env.reset()
            done = False
            while not done:
                action, _ = self.model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = env.step(action)
                done = terminated or truncated
            scores.append(info.get('score', 0))
        
        env.close()
        return np.mean(scores)


def create_v3_model(board_size: int, device: str = 'auto', 
                    prev_model: Optional[PPO] = None) -> PPO:
    """å‰µå»º V3 å¢å¼·æ¨¡å‹
    
    ç›¸æ¯” V2 çš„æ”¹é€²ï¼š
    - æ›´å¤§çš„ç¶²è·¯ï¼š[256, 256, 128] vs V2 çš„ [128, 128, 64]
    - æ›´å¤šæ¢ç´¢ï¼šlearning_rate ç¨é«˜
    - æ”¯æŒé·ç§»å­¸ç¿’ï¼šå¯ä»¥è¼‰å…¥å‰ä¸€éšæ®µçš„æ¨¡å‹
    """
    
    # å‰µå»ºç’°å¢ƒ
    def make_env():
        env = GymSnakeEnvV2(board_size=board_size, render_mode=None)
        env = Monitor(env)
        return env
    
    env = DummyVecEnv([make_env])
    
    # æ¨¡å‹è¶…åƒæ•¸ï¼ˆå¢å¼·ç‰ˆï¼‰
    policy_kwargs = dict(
        net_arch=dict(
            pi=[256, 256, 128],  # Policy network: æ›´å¤§ï¼
            vf=[256, 256, 128]   # Value network: æ›´å¤§ï¼
        ),
        activation_fn=torch.nn.ReLU
    )
    
    # å¦‚æœæœ‰å‰ä¸€éšæ®µçš„æ¨¡å‹ï¼Œé€²è¡Œé·ç§»å­¸ç¿’
    if prev_model is not None:
        print(f"ğŸ”„ é·ç§»å­¸ç¿’ï¼šè¼‰å…¥å‰ä¸€éšæ®µçš„æ¨¡å‹æ¬Šé‡...")
        # å‰µå»ºæ–°æ¨¡å‹ä½†ä½¿ç”¨èˆŠæ¨¡å‹çš„éƒ¨åˆ†åƒæ•¸
        model = PPO(
            "MlpPolicy",
            env,
            policy_kwargs=policy_kwargs,
            learning_rate=3e-4,
            n_steps=2048,
            batch_size=128,  # å¢åŠ  batch size
            n_epochs=15,     # æ›´å¤š epochs
            gamma=0.995,
            gae_lambda=0.95,
            clip_range=0.2,
            ent_coef=0.01,
            vf_coef=0.5,
            max_grad_norm=0.5,
            verbose=1,
            device=device,
            tensorboard_log=f"./logs/ppo_v3_tensorboard/"
        )
        
        # å˜—è©¦è¤‡è£½éƒ¨åˆ†æ¬Šé‡ï¼ˆå¦‚æœæ¶æ§‹å…¼å®¹ï¼‰
        try:
            # é€™è£¡å¯ä»¥æ‰‹å‹•è¤‡è£½æŸäº›å±¤çš„æ¬Šé‡
            # ç°¡å–®ç‰ˆæœ¬ï¼šè®“å®ƒå¾é ­å­¸ç¿’ï¼Œä½†æœ‰ç¶“é©—åŠ é€Ÿ
            print("   æ–°éšæ®µå°‡åˆ©ç”¨å‰éšæ®µçš„å­¸ç¿’ç¶“é©—")
        except Exception as e:
            print(f"   ç„¡æ³•å®Œå…¨é·ç§»æ¬Šé‡ï¼Œå¾é ­é–‹å§‹: {e}")
    
    else:
        # å¾é›¶é–‹å§‹
        model = PPO(
            "MlpPolicy",
            env,
            policy_kwargs=policy_kwargs,
            learning_rate=3e-4,
            n_steps=2048,
            batch_size=128,
            n_epochs=15,
            gamma=0.995,
            gae_lambda=0.95,
            clip_range=0.2,
            ent_coef=0.01,
            vf_coef=0.5,
            max_grad_norm=0.5,
            verbose=1,
            device=device,
            tensorboard_log=f"./logs/ppo_v3_tensorboard/"
        )
    
    return model


def train_curriculum(device: str = 'auto', start_stage: int = 0,
                    n_envs: int = 8, skip_graduation: bool = False):
    """åŸ·è¡Œèª²ç¨‹å­¸ç¿’è¨“ç·´
    
    Args:
        device: 'cpu', 'cuda', æˆ– 'auto'
        start_stage: å¾å“ªå€‹éšæ®µé–‹å§‹ï¼ˆ0=ç¬¬ä¸€éšæ®µï¼‰
        n_envs: ä¸¦è¡Œç’°å¢ƒæ•¸é‡
        skip_graduation: æ˜¯å¦è·³éç•¢æ¥­æª¢æŸ¥ï¼ˆå¼·åˆ¶å®Œæˆæ‰€æœ‰timestepsï¼‰
    """
    
    print("="*70)
    print("ğŸ“ PPO V3: Curriculum Learning (èª²ç¨‹å­¸ç¿’)")
    print("="*70)
    print(f"è¨­å‚™: {device}")
    print(f"ä¸¦è¡Œç’°å¢ƒ: {n_envs}")
    print(f"èµ·å§‹éšæ®µ: {start_stage}")
    print("="*70)
    
    # å‰µå»ºèª²ç¨‹ç®¡ç†å™¨
    curriculum = CurriculumManager()
    curriculum.current_stage_idx = start_stage
    
    # é¡¯ç¤ºèª²ç¨‹è¨ˆåŠƒ
    print("\nğŸ“š èª²ç¨‹è¨ˆåŠƒ:")
    for i, stage in enumerate(curriculum.stages):
        marker = "â†’" if i == start_stage else " "
        print(f"{marker} {stage.name}: {stage.description}")
        print(f"   æ£‹ç›¤: {stage.board_size}x{stage.board_size}, "
              f"è¨“ç·´æ­¥æ•¸: {stage.timesteps:,}, "
              f"ç•¢æ¥­æ¨™æº–: {stage.graduation_score}åˆ†")
    print()
    
    prev_model = None
    
    # é€éšæ®µè¨“ç·´
    for stage_idx in range(start_stage, len(curriculum.stages)):
        curriculum.current_stage_idx = stage_idx
        stage = curriculum.current_stage
        
        print("\n" + "="*70)
        print(f"ğŸ“– é–‹å§‹ {stage.name}")
        print(f"   {stage.description}")
        print(f"   æ£‹ç›¤å¤§å°: {stage.board_size}x{stage.board_size}")
        print(f"   è¨“ç·´æ­¥æ•¸: {stage.timesteps:,}")
        print(f"   ç•¢æ¥­æ¨™æº–: å¹³å‡åˆ†æ•¸ â‰¥ {stage.graduation_score}")
        print("="*70)
        
        # å‰µå»ºæ¨¡å‹
        print("\nğŸ”§ æº–å‚™æ¨¡å‹...")
        model = create_v3_model(stage.board_size, device, prev_model)
        
        # è¨­ç½®æ—¥èªŒ
        log_path = os.path.join(curriculum.base_dir, stage.name, "logs")
        os.makedirs(log_path, exist_ok=True)
        model.set_logger(configure(log_path, ["stdout", "csv", "tensorboard"]))
        
        # è¨­ç½®å›èª¿
        checkpoint_dir = os.path.join(curriculum.base_dir, stage.name, "checkpoints")
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        callbacks = [
            CurriculumCallback(
                curriculum_manager=curriculum,
                eval_freq=10000,
                n_eval_episodes=20,
                verbose=1
            ),
            CheckpointCallback(
                save_freq=50000,
                save_path=checkpoint_dir,
                name_prefix=f"{stage.name}_checkpoint"
            )
        ]
        
        # é–‹å§‹è¨“ç·´
        print(f"\nğŸš€ é–‹å§‹è¨“ç·´ {stage.name}...")
        start_time = time.time()
        
        try:
            model.learn(
                total_timesteps=stage.timesteps,
                callback=callbacks,
                progress_bar=True
            )
        except KeyboardInterrupt:
            print("\nâš ï¸  è¨“ç·´è¢«ç”¨æˆ¶ä¸­æ–·")
            model.save(curriculum.get_model_path())
            print(f"   æ¨¡å‹å·²ä¿å­˜")
            break
        
        training_time = time.time() - start_time
        print(f"\nâœ“ {stage.name} è¨“ç·´å®Œæˆï¼")
        print(f"   è¨“ç·´æ™‚é–“: {training_time/60:.1f} åˆ†é˜")
        
        # ä¿å­˜æœ€çµ‚æ¨¡å‹
        final_model_path = curriculum.get_model_path()
        model.save(final_model_path)
        print(f"   æœ€çµ‚æ¨¡å‹: {final_model_path}")
        
        # æœ€çµ‚è©•ä¼°
        print(f"\nğŸ“Š {stage.name} æœ€çµ‚è©•ä¼°...")
        final_score = evaluate_model(model, stage.board_size, n_episodes=50)
        stage.best_score = max(stage.best_score, final_score)
        
        # æª¢æŸ¥æ˜¯å¦ç•¢æ¥­
        if not skip_graduation:
            if curriculum.check_graduation(final_score):
                stage.completed = True
                # ä¿å­˜ç‚ºæœ€ä½³æ¨¡å‹
                best_path = curriculum.get_best_model_path()
                model.save(best_path)
                print(f"   âœ“ ç•¢æ¥­æ¨¡å‹ä¿å­˜: {best_path}")
            else:
                print(f"\nâŒ æœªé”ç•¢æ¥­æ¨™æº– ({final_score:.1f} < {stage.graduation_score})")
                print(f"   å»ºè­°: å¢åŠ è¨“ç·´æ­¥æ•¸æˆ–èª¿æ•´è¶…åƒæ•¸")
                # è©¢å•æ˜¯å¦ç¹¼çºŒ
                if stage_idx < len(curriculum.stages) - 1:
                    response = input("\næ˜¯å¦ç¹¼çºŒä¸‹ä¸€éšæ®µï¼Ÿ(y/n): ")
                    if response.lower() != 'y':
                        break
        else:
            stage.completed = True
        
        # ä¿å­˜é€²åº¦
        curriculum.save_progress()
        
        # æº–å‚™ä¸‹ä¸€éšæ®µï¼ˆé·ç§»å­¸ç¿’ï¼‰
        if stage.completed and stage_idx < len(curriculum.stages) - 1:
            print(f"\nğŸ“ {stage.name} ç•¢æ¥­ï¼æº–å‚™é€²å…¥ä¸‹ä¸€éšæ®µ...")
            prev_model = model
        
        print("\n")
    
    # è¨“ç·´å®Œæˆ
    print("\n" + "="*70)
    print("ğŸ† èª²ç¨‹å­¸ç¿’è¨“ç·´å®Œæˆï¼")
    print("="*70)
    
    print("\nğŸ“Š å„éšæ®µæˆç¸¾:")
    for stage in curriculum.stages:
        status = "âœ“" if stage.completed else "âœ—"
        print(f"{status} {stage.name}: æœ€ä½³åˆ†æ•¸ {stage.best_score:.1f} / {stage.graduation_score}")
    
    curriculum.save_progress()
    print(f"\nè©³ç´°é€²åº¦å·²ä¿å­˜è‡³: {curriculum.base_dir}/curriculum_progress.txt")


def evaluate_model(model: PPO, board_size: int, n_episodes: int = 20) -> float:
    """è©•ä¼°æ¨¡å‹æ€§èƒ½"""
    env = GymSnakeEnvV2(board_size=board_size, render_mode=None)
    scores = []
    
    for i in range(n_episodes):
        obs, info = env.reset()
        done = False
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated
        scores.append(info.get('score', 0))
    
    env.close()
    mean_score = np.mean(scores)
    std_score = np.std(scores)
    print(f"   è©•ä¼°çµæœ: {mean_score:.1f} Â± {std_score:.1f} (æœ€é«˜: {max(scores)}, æœ€ä½: {min(scores)})")
    return mean_score


def demo_stage(stage_idx: int = -1, n_episodes: int = 5):
    """æ¼”ç¤ºæŸå€‹éšæ®µçš„æ¨¡å‹"""
    curriculum = CurriculumManager()
    
    if stage_idx == -1:
        # æ‰¾åˆ°æœ€å¾Œå®Œæˆçš„éšæ®µ
        for i in range(len(curriculum.stages) - 1, -1, -1):
            model_path = curriculum.get_best_model_path(curriculum.stages[i])
            if os.path.exists(model_path + ".zip"):
                stage_idx = i
                break
    
    if stage_idx < 0 or stage_idx >= len(curriculum.stages):
        print(f"âŒ éšæ®µ {stage_idx} ä¸å­˜åœ¨")
        return
    
    stage = curriculum.stages[stage_idx]
    model_path = curriculum.get_best_model_path(stage)
    
    if not os.path.exists(model_path + ".zip"):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹: {model_path}")
        return
    
    print(f"\nğŸ® æ¼”ç¤º {stage.name} ({stage.board_size}x{stage.board_size})")
    print(f"   è¼‰å…¥æ¨¡å‹: {model_path}")
    
    model = PPO.load(model_path)
    env = GymSnakeEnvV2(board_size=stage.board_size, render_mode="human")
    
    for episode in range(n_episodes):
        print(f"\nå›åˆ {episode + 1}/{n_episodes}")
        obs, info = env.reset()
        done = False
        step_count = 0
        
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated
            step_count += 1
            env.render()
            time.sleep(0.05)
        
        score = info.get('score', 0)
        print(f"   åˆ†æ•¸: {score}, æ­¥æ•¸: {step_count}")
    
    env.close()


def main():
    parser = argparse.ArgumentParser(description="PPO V3 - Curriculum Learning")
    parser.add_argument('--mode', type=str, default='train', 
                       choices=['train', 'demo', 'eval'],
                       help='æ¨¡å¼: train=è¨“ç·´, demo=æ¼”ç¤º, eval=è©•ä¼°')
    parser.add_argument('--device', type=str, default='auto',
                       choices=['cpu', 'cuda', 'auto'],
                       help='è¨“ç·´è¨­å‚™')
    parser.add_argument('--n-envs', type=int, default=8,
                       help='ä¸¦è¡Œç’°å¢ƒæ•¸é‡')
    parser.add_argument('--start-stage', type=int, default=0,
                       help='é–‹å§‹éšæ®µ (0-3)')
    parser.add_argument('--stage', type=int, default=-1,
                       help='æ¼”ç¤º/è©•ä¼°çš„éšæ®µ (-1=æœ€æ–°)')
    parser.add_argument('--n-episodes', type=int, default=5,
                       help='æ¼”ç¤º/è©•ä¼°çš„å›åˆæ•¸')
    parser.add_argument('--skip-graduation', action='store_true',
                       help='è·³éç•¢æ¥­æª¢æŸ¥ï¼Œå¼·åˆ¶å®Œæˆæ‰€æœ‰timesteps')
    
    args = parser.parse_args()
    
    if args.mode == 'train':
        train_curriculum(
            device=args.device,
            start_stage=args.start_stage,
            n_envs=args.n_envs,
            skip_graduation=args.skip_graduation
        )
    
    elif args.mode == 'demo':
        demo_stage(stage_idx=args.stage, n_episodes=args.n_episodes)
    
    elif args.mode == 'eval':
        curriculum = CurriculumManager()
        stage_idx = args.stage if args.stage >= 0 else len(curriculum.stages) - 1
        stage = curriculum.stages[stage_idx]
        model_path = curriculum.get_best_model_path(stage)
        
        if not os.path.exists(model_path + ".zip"):
            print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹: {model_path}")
            return
        
        print(f"\nğŸ“Š è©•ä¼° {stage.name} ({stage.board_size}x{stage.board_size})")
        model = PPO.load(model_path)
        evaluate_model(model, stage.board_size, n_episodes=args.n_episodes)


if __name__ == "__main__":
    main()
