"""
è²ªåƒè›‡AIå¯è¦–åŒ–æ¼”ç¤º
è§€çœ‹è¨“ç·´å¥½çš„AIå¦‚ä½•éŠæˆ²
æ”¯æ´ Q-learningã€PPO V1ã€PPO V2 å’Œ PPO V3 (Curriculum Learning) å››ç¨®æ¨¡å‹
"""

import sys
import time
import os
import glob
import pygame
import numpy as np
from snake_ai import SnakeAI
from envs.snake_game import SnakeGame

# å˜—è©¦å°å…¥ PPO ç›¸é—œæ¨¡çµ„
try:
    from stable_baselines3 import PPO
    from envs.gym_snake_env import GymSnakeEnv
    from envs.gym_snake_env_v2 import GymSnakeEnvV2
    HAS_PPO = True
except ImportError:
    HAS_PPO = False
    print("æ³¨æ„: stable_baselines3 æœªå®‰è£ï¼ŒPPO åŠŸèƒ½ä¸å¯ç”¨")

# UI é¡è‰²å®šç¾©
COLOR_BG = (20, 20, 30)
COLOR_TITLE = (255, 255, 255)
COLOR_TEXT = (200, 200, 200)
COLOR_BUTTON = (50, 100, 150)
COLOR_BUTTON_HOVER = (70, 130, 180)
COLOR_BUTTON_SELECTED = (100, 180, 100)
COLOR_BORDER = (100, 100, 120)


def get_chinese_font(size):
    """ç²å–æ”¯æŒä¸­æ–‡çš„å­—é«”"""
    # Windows å¸¸è¦‹ä¸­æ–‡å­—é«”åˆ—è¡¨ï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰
    chinese_fonts = [
        'microsoftyahei',      # å¾®è»Ÿé›…é»‘
        'microsoftyaheiui',    # å¾®è»Ÿé›…é»‘ UI
        'simsun',              # å®‹é«”
        'simhei',              # é»‘é«”
        'kaiti',               # æ¥·é«”
        'fangsong',            # ä»¿å®‹
        'msgothic',            # MS Gothic (æ—¥æ–‡ï¼Œä½†ä¹Ÿæ”¯æŒä¸­æ–‡)
        'arial',               # Arial Unicode MS
    ]
    
    # å˜—è©¦åŠ è¼‰ä¸­æ–‡å­—é«”
    for font_name in chinese_fonts:
        try:
            font = pygame.font.SysFont(font_name, size)
            # æ¸¬è©¦æ˜¯å¦èƒ½æ¸²æŸ“ä¸­æ–‡
            test_surface = font.render('æ¸¬è©¦', True, (255, 255, 255))
            if test_surface.get_width() > 0:
                return font
        except:
            continue
    
    # å¦‚æœéƒ½å¤±æ•—äº†ï¼Œä½¿ç”¨é»˜èªå­—é«”
    print("è­¦å‘Š: ç„¡æ³•åŠ è¼‰ä¸­æ–‡å­—é«”ï¼Œå¯èƒ½æœƒé¡¯ç¤ºäº‚ç¢¼")
    return pygame.font.Font(None, size)


def list_available_models():
    """æƒæä¸¦åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶"""
    models = {
        'qlearning': [],
        'ppo_v1': [],
        'ppo_v2': [],
        'ppo_v3': []
    }
    
    # Q-learning æ¨¡å‹ (åœ¨æ ¹ç›®éŒ„)
    qlearning_patterns = ["snake_ai_*.pkl"]
    for pattern in qlearning_patterns:
        for f in glob.glob(pattern):
            if os.path.exists(f):
                models['qlearning'].append(f)
    
    # PPO V1 æ¨¡å‹
    ppo_v1_dir = "models/ppo_snake"
    if os.path.exists(ppo_v1_dir):
        # æœ€ä½³æ¨¡å‹
        best = os.path.join(ppo_v1_dir, "best_model", "best_model.zip")
        if os.path.exists(best):
            models['ppo_v1'].append(best)
        # æ‰€æœ‰ checkpoint
        for f in glob.glob(os.path.join(ppo_v1_dir, "*.zip")):
            models['ppo_v1'].append(f)
    
    # PPO V2 æ¨¡å‹
    ppo_v2_dir = "models/ppo_snake_v2"
    if os.path.exists(ppo_v2_dir):
        # æœ€ä½³æ¨¡å‹
        best = os.path.join(ppo_v2_dir, "best_model", "best_model.zip")
        if os.path.exists(best):
            models['ppo_v2'].append(best)
        # æ‰€æœ‰ checkpoint
        for f in glob.glob(os.path.join(ppo_v2_dir, "*.zip")):
            models['ppo_v2'].append(f)
    
    # PPO V3 æ¨¡å‹ï¼ˆèª²ç¨‹å­¸ç¿’ï¼Œ4å€‹éšæ®µï¼‰
    ppo_v3_base = "models/ppo_snake_v3_curriculum"
    if os.path.exists(ppo_v3_base):
        stages = ["Stage1_Novice", "Stage2_Intermediate", "Stage3_Advanced", "Stage4_Master"]
        for stage in stages:
            stage_dir = os.path.join(ppo_v3_base, stage)
            if os.path.exists(stage_dir):
                # æœ€ä½³æ¨¡å‹ï¼ˆç•¢æ¥­æ¨¡å‹ï¼‰
                best = os.path.join(stage_dir, "best_model", "best_model.zip")
                if os.path.exists(best):
                    models['ppo_v3'].append(best)
                # æœ€çµ‚æ¨¡å‹
                final = os.path.join(stage_dir, "model.zip")
                if os.path.exists(final):
                    models['ppo_v3'].append(final)
                # Checkpoints
                checkpoint_dir = os.path.join(stage_dir, "checkpoints")
                if os.path.exists(checkpoint_dir):
                    for f in glob.glob(os.path.join(checkpoint_dir, "*.zip")):
                        models['ppo_v3'].append(f)
    
    return models


class UIButton:
    """pygame UI æŒ‰éˆ•é¡"""
    def __init__(self, x, y, width, height, text, value=None):
        self.rect = pygame.Rect(x, y, width, height)
        self.text = text
        self.value = value if value is not None else text
        self.is_hovered = False
        self.is_selected = False
    
    def draw(self, screen, font):
        # é¸æ“‡é¡è‰²
        if self.is_selected:
            color = COLOR_BUTTON_SELECTED
        elif self.is_hovered:
            color = COLOR_BUTTON_HOVER
        else:
            color = COLOR_BUTTON
        
        # ç¹ªè£½æŒ‰éˆ•
        pygame.draw.rect(screen, color, self.rect, border_radius=8)
        pygame.draw.rect(screen, COLOR_BORDER, self.rect, 2, border_radius=8)
        
        # ç¹ªè£½æ–‡å­—
        text_surface = font.render(self.text, True, COLOR_TITLE)
        text_rect = text_surface.get_rect(center=self.rect.center)
        screen.blit(text_surface, text_rect)
    
    def handle_event(self, event):
        if event.type == pygame.MOUSEMOTION:
            self.is_hovered = self.rect.collidepoint(event.pos)
        elif event.type == pygame.MOUSEBUTTONDOWN:
            if self.is_hovered:
                return True
        return False


class ModelSelector:
    """æ¨¡å‹é¸æ“‡å™¨ UI"""
    def __init__(self, width=800, height=600):
        pygame.init()
        self.width = width
        self.height = height
        self.screen = pygame.display.set_mode((width, height))
        pygame.display.set_caption("é¸æ“‡ AI æ¨¡å‹å’Œè¨­å®š")
        
        # ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„å­—é«”
        self.font_large = get_chinese_font(48)
        self.font_medium = get_chinese_font(36)
        self.font_small = get_chinese_font(24)
        
        self.selected_model_type = None
        self.selected_model_path = None
        self.selected_board_size = None
        
        self.models = list_available_models()
        self.buttons = {}
        self.setup_ui()
    
    def setup_ui(self):
        """è¨­ç½® UI å…ƒç´ """
        # æ¨¡å‹é¡å‹é¸æ“‡æŒ‰éˆ• (ç¬¬ä¸€é )
        button_width = 250
        button_height = 80
        start_y = 180
        spacing = 100
        center_x = self.width // 2 - button_width // 2
        
        self.type_buttons = []
        
        if self.models['qlearning']:
            btn = UIButton(center_x, start_y, button_width, button_height, 
                          f"Q-Learning ({len(self.models['qlearning'])}å€‹)", "qlearning")
            self.type_buttons.append(btn)
        
        if HAS_PPO and self.models['ppo_v1']:
            btn = UIButton(center_x, start_y + spacing, button_width, button_height, 
                          f"PPO V1 ({len(self.models['ppo_v1'])}å€‹)", "ppo_v1")
            self.type_buttons.append(btn)
        
        if HAS_PPO and self.models['ppo_v2']:
            btn = UIButton(center_x, start_y + spacing * 2, button_width, button_height, 
                          f"PPO V2 ({len(self.models['ppo_v2'])}å€‹)", "ppo_v2")
            self.type_buttons.append(btn)
        
        if HAS_PPO and self.models['ppo_v3']:
            btn = UIButton(center_x, start_y + spacing * 3, button_width, button_height, 
                          f"PPO V3 ğŸ“ ({len(self.models['ppo_v3'])}å€‹)", "ppo_v3")
            self.type_buttons.append(btn)
        
        # è¼¸å…¥æ¡†ç›¸é—œï¼ˆè‡ªå®šç¾©æ£‹ç›¤å¤§å°ï¼‰
        self.input_active = True  # ç›´æ¥é€²å…¥è¼¸å…¥æ¨¡å¼
        self.input_text = ""
        self.input_rect = pygame.Rect(center_x, 250, button_width, 60)
    
    def draw_text(self, text, y, font=None, color=COLOR_TEXT):
        """åœ¨å±å¹•ä¸­å¤®ç¹ªè£½æ–‡å­—"""
        if font is None:
            font = self.font_medium
        text_surface = font.render(text, True, color)
        text_rect = text_surface.get_rect(center=(self.width // 2, y))
        self.screen.blit(text_surface, text_rect)
    
    def draw_model_type_selection(self):
        """ç¹ªè£½æ¨¡å‹é¡å‹é¸æ“‡é é¢"""
        self.screen.fill(COLOR_BG)
        
        # æ¨™é¡Œ
        self.draw_text("é¸æ“‡ AI æ¨¡å‹é¡å‹", 80, self.font_large, COLOR_TITLE)
        
        # æŒ‰éˆ•
        for btn in self.type_buttons:
            btn.draw(self.screen, self.font_medium)
        
        # æç¤º
        self.draw_text("ä½¿ç”¨æ»‘é¼ é»æ“Šé¸æ“‡", self.height - 50, self.font_small)
        
        pygame.display.flip()
    
    def draw_model_file_selection(self):
        """ç¹ªè£½å…·é«”æ¨¡å‹æ–‡ä»¶é¸æ“‡é é¢"""
        self.screen.fill(COLOR_BG)
        
        # æ¨™é¡Œ
        type_names = {
            'qlearning': 'Q-Learning',
            'ppo_v1': 'PPO V1',
            'ppo_v2': 'PPO V2',
            'ppo_v3': 'PPO V3 (èª²ç¨‹å­¸ç¿’)'
        }
        title = f"é¸æ“‡ {type_names.get(self.selected_model_type, '')} æ¨¡å‹"
        self.draw_text(title, 60, self.font_large, COLOR_TITLE)
        
        # æ¨¡å‹æ–‡ä»¶æŒ‰éˆ•
        models = self.models[self.selected_model_type]
        button_width = 600
        button_height = 60
        start_y = 150
        center_x = self.width // 2 - button_width // 2
        
        # å‰µå»ºè‡¨æ™‚æŒ‰éˆ•
        if not hasattr(self, 'model_file_buttons'):
            self.model_file_buttons = []
            for i, model_path in enumerate(models):
                # ç°¡åŒ–é¡¯ç¤ºåç¨±
                display_name = os.path.basename(model_path)
                
                # ç‰¹æ®Šæ¨™è¨˜
                if 'best_model' in model_path:
                    display_name = "â˜… " + display_name + " (æœ€ä½³)"
                
                # V3 éšæ®µæ¨™è¨˜
                if self.selected_model_type == 'ppo_v3':
                    if 'Stage1_Novice' in model_path:
                        display_name = "ğŸ“ éšæ®µ1: " + display_name + " (6x6)"
                    elif 'Stage2_Intermediate' in model_path:
                        display_name = "ğŸ“ éšæ®µ2: " + display_name + " (8x8)"
                    elif 'Stage3_Advanced' in model_path:
                        display_name = "ğŸ“ éšæ®µ3: " + display_name + " (10x10)"
                    elif 'Stage4_Master' in model_path:
                        display_name = "ğŸ“ éšæ®µ4: " + display_name + " (12x12)"
                
                btn = UIButton(center_x, start_y + i * 70, button_width, button_height, 
                              display_name[:70], model_path)
                self.model_file_buttons.append(btn)
        
        # ç¹ªè£½æŒ‰éˆ•
        for btn in self.model_file_buttons:
            btn.draw(self.screen, self.font_small)
        
        # è¿”å›æç¤º
        self.draw_text("æŒ‰ ESC è¿”å›ä¸Šä¸€æ­¥", self.height - 50, self.font_small)
        
        pygame.display.flip()
    
    def draw_board_size_selection(self):
        """ç¹ªè£½æ¿å­å¤§å°é¸æ“‡é é¢"""
        self.screen.fill(COLOR_BG)
        
        # æ¨™é¡Œ
        self.draw_text("è¼¸å…¥æ£‹ç›¤å¤§å°", 80, self.font_large, COLOR_TITLE)
        
        # é¡¯ç¤ºå»ºè­°ç¯„åœ
        self.draw_text("å»ºè­°ç¯„åœ: 5-20", 150, self.font_small, COLOR_TEXT)
        self.draw_text("(6=ç°¡å–®, 8=æ¨™æº–, 10=å›°é›£, 12=æ¥µé›£)", 180, self.font_small, COLOR_TEXT)
        
        # ç¹ªè£½è¼¸å…¥æ¡†
        color = COLOR_BUTTON_HOVER
        pygame.draw.rect(self.screen, color, self.input_rect, border_radius=8)
        pygame.draw.rect(self.screen, COLOR_BORDER, self.input_rect, 3, border_radius=8)
        
        # ç¹ªè£½è¼¸å…¥çš„æ–‡å­—
        input_display = self.input_text + "|" if self.input_text or self.input_active else "è«‹è¼¸å…¥æ•¸å­—..."
        text_color = COLOR_TITLE if self.input_text else (150, 150, 150)
        text_surface = self.font_large.render(input_display, True, text_color)
        text_rect = text_surface.get_rect(center=self.input_rect.center)
        self.screen.blit(text_surface, text_rect)
        
        # æç¤ºæŒ‰ Enter ç¢ºèª
        self.draw_text("æŒ‰ Enter ç¢ºèª", self.input_rect.y + 100, self.font_medium, COLOR_TEXT)
        self.draw_text("æŒ‰ ESC è¿”å›ä¸Šä¸€æ­¥", self.height - 50, self.font_small)
        
        pygame.display.flip()
    
    def run(self):
        """é‹è¡Œé¸æ“‡å™¨"""
        clock = pygame.time.Clock()
        stage = 'type'  # type -> file -> board -> done
        
        running = True
        while running:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    pygame.quit()
                    return None, None, None
                
                if event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_ESCAPE:
                        if stage == 'file':
                            stage = 'type'
                            self.model_file_buttons = []
                        elif stage == 'board':
                            stage = 'file'
                            self.input_text = ""
                        elif stage == 'type':
                            pygame.quit()
                            return None, None, None
                    
                    # è™•ç†è‡ªå®šç¾©å¤§å°è¼¸å…¥
                    elif stage == 'board':
                        if event.key == pygame.K_RETURN:
                            # ç¢ºèªè¼¸å…¥
                            if self.input_text:
                                try:
                                    size = int(self.input_text)
                                    if 5 <= size <= 20:
                                        self.selected_board_size = size
                                        pygame.quit()
                                        return self.selected_model_type, self.selected_model_path, self.selected_board_size
                                    else:
                                        print(f"è­¦å‘Š: æ£‹ç›¤å¤§å°å¿…é ˆåœ¨ 5-20 ä¹‹é–“ï¼Œæ‚¨è¼¸å…¥çš„æ˜¯ {size}")
                                        self.input_text = ""
                                except ValueError:
                                    print(f"è­¦å‘Š: è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
                                    self.input_text = ""
                        elif event.key == pygame.K_BACKSPACE:
                            self.input_text = self.input_text[:-1]
                        elif event.unicode.isdigit() and len(self.input_text) < 2:
                            self.input_text += event.unicode
                
                # è™•ç†ä¸åŒéšæ®µçš„äº‹ä»¶
                if stage == 'type':
                    for btn in self.type_buttons:
                        btn.handle_event(event)
                        if event.type == pygame.MOUSEBUTTONDOWN and btn.is_hovered:
                            self.selected_model_type = btn.value
                            stage = 'file'
                            break
                
                elif stage == 'file':
                    for btn in self.model_file_buttons:
                        btn.handle_event(event)
                        if event.type == pygame.MOUSEBUTTONDOWN and btn.is_hovered:
                            self.selected_model_path = btn.value
                            stage = 'board'
                            break
                
                # board éšæ®µä¸éœ€è¦è™•ç†æ»‘é¼ é»æ“Šï¼ˆåªç”¨éµç›¤è¼¸å…¥ï¼‰
            
            # ç¹ªè£½ç•¶å‰éšæ®µ
            if stage == 'type':
                self.draw_model_type_selection()
            elif stage == 'file':
                self.draw_model_file_selection()
            elif stage == 'board':
                self.draw_board_size_selection()
            
            clock.tick(60)
        
        pygame.quit()
        return None, None, None



def get_user_choice_board_size():
    """è®“ç”¨æˆ¶é¸æ“‡æ£‹ç›¤å¤§å°"""
    print("\nè«‹é¸æ“‡æ£‹ç›¤å¤§å°:")
    print("  1. 6x6 (ç°¡å–®)")
    print("  2. 8x8 (æ¨™æº–) æ¨è–¦")
    print("  3. 10x10 (å›°é›£)")
    print("  4. 12x12 (æ¥µé›£)")
    
    while True:
        try:
            choice = input("\nè«‹è¼¸å…¥é¸æ“‡ (1-4ï¼Œç›´æ¥æŒ‰Enteré¸æ“‡8x8): ").strip()
            
            if choice == '' or choice == '2':
                return 8
            elif choice == '1':
                return 6
            elif choice == '3':
                return 10
            elif choice == '4':
                return 12
            else:
                print("ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥")
        except ValueError:
            print("ç„¡æ•ˆè¼¸å…¥ï¼Œè«‹è¼¸å…¥æ•¸å­—")

def watch_ai_play(board_size=None, model_path=None):
    """è§€çœ‹AIéŠæˆ²ä¸¦é¡¯ç¤ºæ±ºç­–éç¨‹"""
    
    # è®“ç”¨æˆ¶é¸æ“‡æ£‹ç›¤å¤§å°
    if board_size is None:
        board_size = get_user_choice_board_size()
    
    # è¼‰å…¥è¨“ç·´å¥½çš„AI
    ai = SnakeAI(board_size=board_size)
    
    # å˜—è©¦è¼‰å…¥æœ€ä½³æ¨¡å‹
    if model_path:
        models_to_try = [model_path]
    else:
        models_to_try = [
            "snake_ai_standard.pkl",
            "snake_ai_quick.pkl", 
            "snake_ai_final.pkl"
        ]
    
    model_loaded = False
    for model_file in models_to_try:
        try:
            ai.load_model(model_file)
            print(f"æˆåŠŸè¼‰å…¥æ¨¡å‹: {model_file}")
            model_loaded = True
            break
        except:
            continue
    
    if not model_loaded:
        print("è­¦å‘Š: æœªæ‰¾åˆ°é è¨“ç·´æ¨¡å‹ï¼Œä½¿ç”¨éš¨æ©ŸAI")
    
    # å‰µå»ºéŠæˆ²å¯¦ä¾‹
    game = SnakeGame(silent_mode=False, board_size=ai.board_size)
    
    action_names = {0: "UP", 1: "LEFT", 2: "RIGHT", 3: "DOWN"}
    
    print("\n" + "="*60)
    print(f"=== AIè²ªåƒè›‡æ¼”ç¤º (æ£‹ç›¤: {board_size}x{board_size}) ===")
    print("="*60)
    print("è§€çœ‹AIå¦‚ä½•ä½¿ç”¨è²çˆ¾æ›¼æ–¹ç¨‹å­¸åˆ°çš„ç­–ç•¥")
    print("æŒ‰ESCéµæˆ–é—œé–‰çª—å£çµæŸæ¼”ç¤º")
    print("æŒ‰ç©ºæ ¼éµæš«åœ/ç¹¼çºŒ")
    print("="*60)
    
    try:
        game_count = 1
        
        while True:
            print(f"\n--- éŠæˆ² {game_count} é–‹å§‹ ---")
            
            # é‡ç½®éŠæˆ²
            game.reset()
            state = ai.get_state(game)
            steps = 0
            max_steps = ai.board_size * ai.board_size * 3
            
            # éŠæˆ²å¾ªç’°
            while steps < max_steps:
                # AIé¸æ“‡å‹•ä½œ
                action = ai.choose_action(state, training=False)
                q_values = ai.get_q_values(state)
                
                # é¡¯ç¤ºAIçš„æ€è€ƒéç¨‹
                print(f"æ­¥é©Ÿ {steps+1:3d}: å‹•ä½œ={action_names[action]:5s} "
                      f"Qå€¼=[{q_values[0]:6.2f}, {q_values[1]:6.2f}, {q_values[2]:6.2f}, {q_values[3]:6.2f}] "
                      f"åˆ†æ•¸={game.score:3d}")
                
                # åŸ·è¡Œå‹•ä½œ
                done, info = game.step(action)
                
                # æ¸²æŸ“éŠæˆ²
                if hasattr(game, 'render') and game.screen:
                    game.render()
                
                # æª¢æŸ¥pygameäº‹ä»¶
                for event in pygame.event.get():
                    if event.type == pygame.QUIT:
                        pygame.quit()
                        return
                    elif event.type == pygame.KEYDOWN:
                        if event.key == pygame.K_ESCAPE:
                            pygame.quit()
                            return
                        elif event.key == pygame.K_SPACE:
                            # ç©ºæ ¼éµæš«åœ/ç¹¼çºŒ
                            input("æŒ‰Enterç¹¼çºŒ...")
                
                if done:
                    print(f"éŠæˆ²çµæŸ! æœ€çµ‚åˆ†æ•¸: {game.score}, ç¸½æ­¥æ•¸: {steps+1}")
                    
                    # ç­‰å¾…ä¸€ä¸‹å†é–‹å§‹ä¸‹ä¸€å±€
                    time.sleep(2)
                    break
                
                # æ›´æ–°ç‹€æ…‹
                state = ai.get_state(game)
                steps += 1
                
                # æ§åˆ¶éŠæˆ²é€Ÿåº¦
                time.sleep(0.2)
            
            game_count += 1
            
            if game_count > 5:  # æœ€å¤šè§€çœ‹5å±€
                print("æ¼”ç¤ºçµæŸ")
                break
                
    except KeyboardInterrupt:
        print("\næ¼”ç¤ºè¢«ç”¨æˆ¶ä¸­æ–·")
    
    finally:
        if pygame.get_init():
            pygame.quit()

def compare_before_after_training():
    """æ¯”è¼ƒè¨“ç·´å‰å¾Œçš„AIè¡¨ç¾"""
    
    print("=== è¨“ç·´å‰å¾Œæ¯”è¼ƒ ===")
    
    # æœªè¨“ç·´çš„AI
    untrained_ai = SnakeAI(board_size=8)
    
    # è¨“ç·´å¥½çš„AI
    trained_ai = SnakeAI(board_size=8)
    try:
        trained_ai.load_model("snake_ai_standard.pkl")
        print("è¼‰å…¥è¨“ç·´å¥½çš„AIæ¨¡å‹")
    except:
        print("è­¦å‘Š: æœªæ‰¾åˆ°è¨“ç·´å¥½çš„æ¨¡å‹")
        return
    
    # æ¸¬è©¦å…©å€‹AI
    def test_ai_performance(ai, name, num_games=5):
        scores = []
        print(f"\næ¸¬è©¦ {name}:")
        
        for i in range(num_games):
            score, steps = ai.play_game(render=False)
            scores.append(score)
            print(f"  éŠæˆ² {i+1}: åˆ†æ•¸={score}, æ­¥æ•¸={steps}")
        
        avg_score = sum(scores) / len(scores)
        print(f"  å¹³å‡åˆ†æ•¸: {avg_score:.2f}")
        return scores
    
    untrained_scores = test_ai_performance(untrained_ai, "æœªè¨“ç·´AI")
    trained_scores = test_ai_performance(trained_ai, "è¨“ç·´å¾ŒAI")
    
    print(f"\n=== æ¯”è¼ƒçµæœ ===")
    print(f"æœªè¨“ç·´AIå¹³å‡åˆ†æ•¸: {sum(untrained_scores)/len(untrained_scores):.2f}")
    print(f"è¨“ç·´å¾ŒAIå¹³å‡åˆ†æ•¸: {sum(trained_scores)/len(trained_scores):.2f}")
    print(f"æ”¹é€²å€æ•¸: {(sum(trained_scores)/len(trained_scores)) / max(1, sum(untrained_scores)/len(untrained_scores)):.2f}x")

def analyze_ai_strategy():
    """åˆ†æAIå­¸åˆ°çš„ç­–ç•¥"""
    
    ai = SnakeAI(board_size=8)
    try:
        ai.load_model("snake_ai_standard.pkl")
    except:
        print("éœ€è¦å…ˆè¨“ç·´AIæ¨¡å‹")
        return
    
    print("=== AIç­–ç•¥åˆ†æ ===")
    print(f"Qè¡¨å¤§å°: {len(ai.q_table)} å€‹ç‹€æ…‹")
    
    # åˆ†æQå€¼åˆ†å¸ƒ
    all_q_values = []
    for state_q_values in ai.q_table.values():
        all_q_values.extend(state_q_values)
    
    import numpy as np
    print(f"Qå€¼çµ±è¨ˆ:")
    print(f"  æœ€å¤§å€¼: {max(all_q_values):.2f}")
    print(f"  æœ€å°å€¼: {min(all_q_values):.2f}")
    print(f"  å¹³å‡å€¼: {np.mean(all_q_values):.2f}")
    print(f"  æ¨™æº–å·®: {np.std(all_q_values):.2f}")
    
    # æ‰¾å‡ºæœ€é‡è¦çš„ç‹€æ…‹
    print(f"\næœ€æœ‰åƒ¹å€¼çš„ç‹€æ…‹-å‹•ä½œå°:")
    state_action_values = []
    action_names = {0: "UP", 1: "LEFT", 2: "RIGHT", 3: "DOWN"}
    
    for state, q_values in ai.q_table.items():
        for action, q_value in enumerate(q_values):
            state_action_values.append((q_value, state, action))
    
    state_action_values.sort(reverse=True)
    
    for i, (q_value, state, action) in enumerate(state_action_values[:5]):
        print(f"  {i+1}. Qå€¼={q_value:.2f}, å‹•ä½œ={action_names[action]}, ç‹€æ…‹={state}")


def watch_ppo_play(version='v1', board_size=None, model_path=None):
    """è§€çœ‹ PPO AI éŠæˆ²ä¸¦é¡¯ç¤ºæ±ºç­–éç¨‹
    
    Args:
        version: 'v1', 'v2', æˆ– 'v3'ï¼Œé¸æ“‡ PPO ç‰ˆæœ¬
        board_size: æ£‹ç›¤å¤§å°ï¼ŒNone è¡¨ç¤ºè®“ç”¨æˆ¶é¸æ“‡
        model_path: æ¨¡å‹è·¯å¾‘ï¼ŒNone è¡¨ç¤ºè‡ªå‹•æœå°‹
    """
    
    if not HAS_PPO:
        print("éŒ¯èª¤: éœ€è¦å®‰è£ stable_baselines3 æ‰èƒ½ä½¿ç”¨ PPO æ¨¡å‹")
        print("è«‹åŸ·è¡Œ: pip install stable-baselines3 torch")
        return
    
    # è®“ç”¨æˆ¶é¸æ“‡æ£‹ç›¤å¤§å°
    if board_size is None:
        board_size = get_user_choice_board_size()
    
    # å˜—è©¦è¼‰å…¥ PPO æ¨¡å‹
    if model_path:
        models_to_try = [model_path]
    elif version == 'v3':
        # V3 æ ¹æ“šæ£‹ç›¤å¤§å°é¸æ“‡å°æ‡‰çš„éšæ®µæ¨¡å‹
        stage_map = {
            6: "Stage1_Novice",
            8: "Stage2_Intermediate",
            10: "Stage3_Advanced",
            12: "Stage4_Master"
        }
        stage = stage_map.get(board_size, "Stage2_Intermediate")
        models_to_try = [
            f"models/ppo_snake_v3_curriculum/{stage}/best_model/best_model.zip",
            f"models/ppo_snake_v3_curriculum/{stage}/model.zip",
        ]
    elif version == 'v2':
        models_to_try = [
            "models/ppo_snake_v2/best_model/best_model.zip",
            "models/ppo_snake_v2/ppo_snake_v2_final.zip",
        ]
    else:  # v1
        models_to_try = [
            "models/ppo_snake/best_model/best_model.zip",
            "models/ppo_snake/ppo_snake_final.zip",
        ]
    
    model = None
    model_path_loaded = None
    for path in models_to_try:
        if os.path.exists(path):
            try:
                model = PPO.load(path)
                model_path_loaded = path
                print(f"æˆåŠŸè¼‰å…¥ PPO {version.upper()} æ¨¡å‹: {path}")
                break
            except Exception as e:
                print(f"è¼‰å…¥ {path} å¤±æ•—: {e}")
                continue
    
    if model is None:
        print(f"è­¦å‘Š: æœªæ‰¾åˆ° PPO {version.upper()} é è¨“ç·´æ¨¡å‹")
        print(f"è«‹å…ˆè¨“ç·´æ¨¡å‹:")
        if version == 'v3':
            print(f"  python snake_ai_ppo_v3.py --mode train")
        elif version == 'v2':
            print(f"  python snake_ai_ppo_v2.py --mode train --timesteps 500000 --board-size {board_size}")
        else:
            print(f"  python snake_ai_ppo.py --mode train --timesteps 100000 --board-size {board_size}")
        return
    
    # å‰µå»ºéŠæˆ²ç’°å¢ƒ
    if version == 'v3':
        env = GymSnakeEnvV2(board_size=board_size, render_mode="human")
        version_name = "PPO V3 (Curriculum Learning)"
        features = [
            "èª²ç¨‹å­¸ç¿’ï¼šå¾ªåºæ¼¸é€²è¨“ç·´",
            "é·ç§»å­¸ç¿’ï¼šçŸ¥è­˜é€ç´šå‚³é",
            "æ›´å¤§ç¥ç¶“ç¶²è·¯ [256, 256, 128]",
            "16-d è§€å¯Ÿç©ºé–“ + V2 çå‹µå¡‘å½¢",
        ]
    elif version == 'v2':
        env = GymSnakeEnvV2(board_size=board_size, render_mode="human")
        version_name = "PPO V2 (Enhanced Collision Avoidance)"
        features = [
            "ä½¿ç”¨æ·±åº¦ç¥ç¶“ç¶²è·¯å­¸ç¿’ç­–ç•¥",
            "æ¼¸é€²å¼ç¢°æ’æ‡²ç½° (é ¸éƒ¨ -50)",
            "16-d è§€å¯Ÿç©ºé–“ (å«èº«é«”è·é›¢æ„ŸçŸ¥)",
            "å›°å¢ƒåµæ¸¬èˆ‡é¿å…",
        ]
    else:
        env = GymSnakeEnv(board_size=board_size, render_mode="human")
        version_name = "PPO V1 (Basic)"
        features = [
            "ä½¿ç”¨æ·±åº¦ç¥ç¶“ç¶²è·¯å­¸ç¿’ç­–ç•¥",
            "ç©©å®šä¸”é«˜æ•ˆçš„è¨“ç·´éç¨‹",
            "12-d è§€å¯Ÿç©ºé–“",
            "åŸºç¤çå‹µå¡‘å½¢",
        ]
    
    action_names = {0: "UP", 1: "LEFT", 2: "RIGHT", 3: "DOWN"}
    
    print("\n" + "="*70)
    print(f"{version_name} AI æ¼”ç¤º")
    print(f"æ£‹ç›¤å¤§å°: {board_size}x{board_size}")
    print("="*70)
    print("ç‰¹é»:")
    for feature in features:
        print(f"  â€¢ {feature}")
    print("="*70)
    print("æ“ä½œèªªæ˜:")
    print("  â€¢ æŒ‰ ESC éµæˆ–é—œé–‰çª—å£çµæŸæ¼”ç¤º")
    print("  â€¢ æŒ‰ ç©ºæ ¼éµ æš«åœ/ç¹¼çºŒ")
    print("="*70)
    
    try:
        game_count = 1
        
        while True:
            print(f"\n--- éŠæˆ² {game_count} é–‹å§‹ ---")
            
            # é‡ç½®ç’°å¢ƒ
            obs, info = env.reset()
            done = False
            steps = 0
            total_reward = 0
            
            # éŠæˆ²å¾ªç’°
            while not done:
                # PPO é¸æ“‡å‹•ä½œ (deterministic=True è¡¨ç¤ºä½¿ç”¨ç¢ºå®šæ€§ç­–ç•¥)
                action, _states = model.predict(obs, deterministic=True)
                action = int(action)
                
                # é¡¯ç¤º AI çš„æ±ºç­–
                print(f"æ­¥é©Ÿ {steps+1:3d}: å‹•ä½œ={action_names[action]:5s} "
                      f"åˆ†æ•¸={info.get('score', 0):3d} "
                      f"è›‡é•·={info.get('snake_length', 0):3d}")
                
                # åŸ·è¡Œå‹•ä½œ
                obs, reward, terminated, truncated, info = env.step(action)
                total_reward += reward
                done = terminated or truncated
                
                # æ¸²æŸ“éŠæˆ²
                env.render()
                
                # æª¢æŸ¥ pygame äº‹ä»¶
                for event in pygame.event.get():
                    if event.type == pygame.QUIT:
                        pygame.quit()
                        env.close()
                        return
                    elif event.type == pygame.KEYDOWN:
                        if event.key == pygame.K_ESCAPE:
                            pygame.quit()
                            env.close()
                            return
                        elif event.key == pygame.K_SPACE:
                            # ç©ºæ ¼éµæš«åœ/ç¹¼çºŒ
                            input("æŒ‰ Enter ç¹¼çºŒ...")
                
                steps += 1
                
                # æ§åˆ¶éŠæˆ²é€Ÿåº¦
                time.sleep(0.15)
            
            # éŠæˆ²çµæŸçµ±è¨ˆ
            final_score = info.get('score', 0)
            final_length = info.get('snake_length', 0)
            near_misses = info.get('near_miss_count', 0) if version == 'v2' else 'N/A'
            
            print(f"\néŠæˆ²çµæŸçµ±è¨ˆ:")
            print(f"  æœ€çµ‚åˆ†æ•¸: {final_score}")
            print(f"  è›‡çš„é•·åº¦: {final_length}")
            print(f"  ç¸½æ­¥æ•¸: {steps}")
            print(f"  ç¸½çå‹µ: {total_reward:.2f}")
            print(f"  æˆåŠŸç‡: {final_score}/{board_size**2-1} ({final_score/(board_size**2-1)*100:.1f}%)")
            if version == 'v2':
                print(f"  Near-miss æ¬¡æ•¸: {near_misses}")
            
            # ç­‰å¾…ä¸€ä¸‹å†é–‹å§‹ä¸‹ä¸€å±€
            time.sleep(2)
            
            game_count += 1
            
            if game_count > 5:  # æœ€å¤šè§€çœ‹ 5 å±€
                print("\næ¼”ç¤ºçµæŸ")
                break
                
    except KeyboardInterrupt:
        print("\næ¼”ç¤ºè¢«ç”¨æˆ¶ä¸­æ–·")
    
    finally:
        env.close()
        if pygame.get_init():
            pygame.quit()


def compare_qlearning_vs_ppo():
    """æ¯”è¼ƒ Q-learning å’Œ PPO å…©ç¨®æ–¹æ³•çš„è¡¨ç¾"""
    
    print("\n" + "="*60)
    print("Q-learning vs PPO æ€§èƒ½æ¯”è¼ƒ")
    print("="*60)
    
    # æ¸¬è©¦ Q-learning
    print("\næ¸¬è©¦ Q-learning AI...")
    qlearning_ai = SnakeAI(board_size=8)
    try:
        qlearning_ai.load_model("snake_ai_standard.pkl")
        print("âœ“ è¼‰å…¥ Q-learning æ¨¡å‹æˆåŠŸ")
        
        qlearning_scores = []
        for i in range(10):
            score, steps = qlearning_ai.play_game(render=False)
            qlearning_scores.append(score)
            print(f"  éŠæˆ² {i+1}: åˆ†æ•¸={score}, æ­¥æ•¸={steps}")
        
        qlearning_avg = np.mean(qlearning_scores)
        qlearning_max = max(qlearning_scores)
        print(f"  å¹³å‡åˆ†æ•¸: {qlearning_avg:.2f}")
        print(f"  æœ€é«˜åˆ†æ•¸: {qlearning_max}")
        
    except Exception as e:
        print(f"âœ— Q-learning æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        qlearning_avg = 0
        qlearning_max = 0
        qlearning_scores = []
    
    # æ¸¬è©¦ PPO
    if HAS_PPO:
        print("\næ¸¬è©¦ PPO AI...")
        
        models_to_try = [
            "models/ppo_snake/best_model/best_model.zip",
            "models/ppo_snake/ppo_snake_final.zip",
        ]
        
        ppo_model = None
        for path in models_to_try:
            if os.path.exists(path):
                try:
                    ppo_model = PPO.load(path)
                    print(f"âœ“ è¼‰å…¥ PPO æ¨¡å‹æˆåŠŸ: {path}")
                    break
                except:
                    continue
        
        if ppo_model is not None:
            env = GymSnakeEnv(board_size=8, render_mode=None)
            ppo_scores = []
            
            for i in range(10):
                obs, info = env.reset()
                done = False
                steps = 0
                
                while not done:
                    action, _ = ppo_model.predict(obs, deterministic=True)
                    obs, reward, terminated, truncated, info = env.step(action)
                    done = terminated or truncated
                    steps += 1
                
                score = info.get('score', 0)
                ppo_scores.append(score)
                print(f"  éŠæˆ² {i+1}: åˆ†æ•¸={score}, æ­¥æ•¸={steps}")
            
            ppo_avg = np.mean(ppo_scores)
            ppo_max = max(ppo_scores)
            print(f"  å¹³å‡åˆ†æ•¸: {ppo_avg:.2f}")
            print(f"  æœ€é«˜åˆ†æ•¸: {ppo_max}")
            
            env.close()
        else:
            print("âœ— PPO æ¨¡å‹è¼‰å…¥å¤±æ•—")
            ppo_avg = 0
            ppo_max = 0
            ppo_scores = []
    else:
        print("\nâœ— PPO ä¸å¯ç”¨ï¼ˆéœ€è¦å®‰è£ stable_baselines3ï¼‰")
        ppo_avg = 0
        ppo_max = 0
        ppo_scores = []
    
    # é¡¯ç¤ºæ¯”è¼ƒçµæœ
    print("\n" + "="*60)
    print("æ¯”è¼ƒçµæœç¸½çµ")
    print("="*60)
    
    print(f"\n{'æ–¹æ³•':<15} {'å¹³å‡åˆ†æ•¸':<12} {'æœ€é«˜åˆ†æ•¸':<12} {'å„ªå‹¢'}")
    print("-" * 60)
    print(f"{'Q-learning':<15} {qlearning_avg:<12.2f} {qlearning_max:<12} å‚³çµ±æ–¹æ³•ï¼Œç©©å®š")
    print(f"{'PPO':<15} {ppo_avg:<12.2f} {ppo_max:<12} æ·±åº¦å­¸ç¿’ï¼Œæ“´å±•æ€§å¼·")
    
    if ppo_avg > 0 and qlearning_avg > 0:
        improvement = (ppo_avg - qlearning_avg) / qlearning_avg * 100
        print(f"\nPPO ç›¸æ¯” Q-learning çš„æ”¹é€²: {improvement:+.1f}%")
    
    print("\n" + "="*60)
    print("ç®—æ³•ç‰¹æ€§æ¯”è¼ƒ:")
    print("="*60)
    print("\nQ-learning:")
    print("  âœ“ ç°¡å–®æ˜“æ‡‚ï¼Œå¯¦ç¾ç°¡å–®")
    print("  âœ“ è¨“ç·´å¿«é€Ÿï¼ˆå°æ£‹ç›¤ï¼‰")
    print("  âœ— ç‹€æ…‹ç©ºé–“çˆ†ç‚¸ï¼ˆå¤§æ£‹ç›¤ï¼‰")
    print("  âœ— é›£ä»¥æ“´å±•åˆ°è¤‡é›œå•é¡Œ")
    
    print("\nPPO:")
    print("  âœ“ ä½¿ç”¨æ·±åº¦ç¥ç¶“ç¶²è·¯ï¼Œæ“´å±•æ€§å¼·")
    print("  âœ“ å¯è™•ç†å¤§è¦æ¨¡ç‹€æ…‹ç©ºé–“")
    print("  âœ“ æ”¯æ´å¤šé€²ç¨‹ä¸¦è¡Œè¨“ç·´")
    print("  âœ“ ç¾ä»£ RL æ¨™æº–æ–¹æ³•")
    print("  âœ— éœ€è¦æ›´å¤šè¨“ç·´æ™‚é–“")
    print("  âœ— éœ€è¦èª¿æ•´è¶…åƒæ•¸")
    print("="*60)

def compare_all_methods():
    """æ¯”è¼ƒ Q-learningã€PPO V1 å’Œ PPO V2 ä¸‰ç¨®æ–¹æ³•çš„è¡¨ç¾"""
    
    print("\n" + "="*70)
    print("Q-learning vs PPO V1 vs PPO V2 æ€§èƒ½æ¯”è¼ƒ")
    print("="*70)
    
    # è®“ç”¨æˆ¶é¸æ“‡æ£‹ç›¤å¤§å°
    board_size = get_user_choice_board_size()
    print(f"\nä½¿ç”¨æ£‹ç›¤å¤§å°: {board_size}x{board_size}")
    
    num_games = 10
    results = {}
    
    # æ¸¬è©¦ Q-learning
    print("\n" + "â”€"*70)
    print("æ¸¬è©¦ Q-learning AI...")
    print("â”€"*70)
    qlearning_ai = SnakeAI(board_size=board_size)
    try:
        qlearning_ai.load_model("snake_ai_standard.pkl")
        print("âœ“ è¼‰å…¥ Q-learning æ¨¡å‹æˆåŠŸ")
        
        qlearning_scores = []
        for i in range(num_games):
            score, steps = qlearning_ai.play_game(render=False)
            qlearning_scores.append(score)
            print(f"  éŠæˆ² {i+1:2d}: åˆ†æ•¸={score:3d}, æ­¥æ•¸={steps:4d}")
        
        results['Q-learning'] = {
            'scores': qlearning_scores,
            'avg': np.mean(qlearning_scores),
            'max': max(qlearning_scores),
            'min': min(qlearning_scores),
            'std': np.std(qlearning_scores)
        }
        print(f"  å¹³å‡åˆ†æ•¸: {results['Q-learning']['avg']:.2f} Â± {results['Q-learning']['std']:.2f}")
        
    except Exception as e:
        print(f"âœ— Q-learning æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        results['Q-learning'] = None
    
    # æ¸¬è©¦ PPO V1
    print("\n" + "â”€"*70)
    print("æ¸¬è©¦ PPO V1 AI...")
    print("â”€"*70)
    
    ppo_v1_models = [
        "models/ppo_snake/best_model/best_model.zip",
        "models/ppo_snake/ppo_snake_final.zip",
    ]
    
    ppo_v1_model = None
    for path in ppo_v1_models:
        if os.path.exists(path):
            try:
                ppo_v1_model = PPO.load(path)
                print(f"âœ“ è¼‰å…¥ PPO V1 æ¨¡å‹æˆåŠŸ: {path}")
                break
            except:
                continue
    
    if ppo_v1_model is not None:
        env = GymSnakeEnv(board_size=board_size, render_mode=None)
        ppo_v1_scores = []
        
        for i in range(num_games):
            obs, info = env.reset()
            done = False
            steps = 0
            
            while not done:
                action, _ = ppo_v1_model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = env.step(action)
                done = terminated or truncated
                steps += 1
            
            score = info.get('score', 0)
            ppo_v1_scores.append(score)
            print(f"  éŠæˆ² {i+1:2d}: åˆ†æ•¸={score:3d}, æ­¥æ•¸={steps:4d}")
        
        results['PPO V1'] = {
            'scores': ppo_v1_scores,
            'avg': np.mean(ppo_v1_scores),
            'max': max(ppo_v1_scores),
            'min': min(ppo_v1_scores),
            'std': np.std(ppo_v1_scores)
        }
        print(f"  å¹³å‡åˆ†æ•¸: {results['PPO V1']['avg']:.2f} Â± {results['PPO V1']['std']:.2f}")
        
        env.close()
    else:
        print("âœ— PPO V1 æ¨¡å‹è¼‰å…¥å¤±æ•—")
        results['PPO V1'] = None
    
    # æ¸¬è©¦ PPO V2
    print("\n" + "â”€"*70)
    print("æ¸¬è©¦ PPO V2 AI (Enhanced Collision Avoidance)...")
    print("â”€"*70)
    
    ppo_v2_models = [
        "models/ppo_snake_v2/best_model/best_model.zip",
        "models/ppo_snake_v2/ppo_snake_v2_final.zip",
    ]
    
    ppo_v2_model = None
    for path in ppo_v2_models:
        if os.path.exists(path):
            try:
                ppo_v2_model = PPO.load(path)
                print(f"âœ“ è¼‰å…¥ PPO V2 æ¨¡å‹æˆåŠŸ: {path}")
                break
            except:
                continue
    
    if ppo_v2_model is not None:
        env = GymSnakeEnvV2(board_size=board_size, render_mode=None)
        ppo_v2_scores = []
        ppo_v2_near_misses = []
        
        for i in range(num_games):
            obs, info = env.reset()
            done = False
            steps = 0
            
            while not done:
                action, _ = ppo_v2_model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = env.step(action)
                done = terminated or truncated
                steps += 1
            
            score = info.get('score', 0)
            near_miss = info.get('near_miss_count', 0)
            ppo_v2_scores.append(score)
            ppo_v2_near_misses.append(near_miss)
            print(f"  éŠæˆ² {i+1:2d}: åˆ†æ•¸={score:3d}, æ­¥æ•¸={steps:4d}, Near-miss={near_miss:2d}")
        
        results['PPO V2'] = {
            'scores': ppo_v2_scores,
            'avg': np.mean(ppo_v2_scores),
            'max': max(ppo_v2_scores),
            'min': min(ppo_v2_scores),
            'std': np.std(ppo_v2_scores),
            'near_misses': np.mean(ppo_v2_near_misses)
        }
        print(f"  å¹³å‡åˆ†æ•¸: {results['PPO V2']['avg']:.2f} Â± {results['PPO V2']['std']:.2f}")
        print(f"  å¹³å‡ Near-miss: {results['PPO V2']['near_misses']:.1f}")
        
        env.close()
    else:
        print("âœ— PPO V2 æ¨¡å‹è¼‰å…¥å¤±æ•—")
        results['PPO V2'] = None
    
    # é¡¯ç¤ºæ¯”è¼ƒçµæœ
    print("\n" + "="*70)
    print("æ¯”è¼ƒçµæœç¸½çµ")
    print("="*70)
    
    print(f"\n{'æ–¹æ³•':<15} {'å¹³å‡åˆ†æ•¸':<15} {'æœ€é«˜åˆ†':<10} {'æœ€ä½åˆ†':<10} {'æ¨™æº–å·®':<10}")
    print("â”€" * 70)
    
    for method, data in results.items():
        if data:
            print(f"{method:<15} {data['avg']:<15.2f} {data['max']:<10} {data['min']:<10} {data['std']:<10.2f}")
        else:
            print(f"{method:<15} {'N/A':<15} {'N/A':<10} {'N/A':<10} {'N/A':<10}")
    
    # è¨ˆç®—æ”¹é€²ç™¾åˆ†æ¯”
    print("\n" + "="*70)
    print("æ”¹é€²åˆ†æ")
    print("="*70)
    
    if results.get('Q-learning') and results.get('PPO V1'):
        improvement = (results['PPO V1']['avg'] - results['Q-learning']['avg']) / max(results['Q-learning']['avg'], 0.01) * 100
        print(f"\nPPO V1 ç›¸æ¯” Q-learning: {improvement:+.1f}%")
    
    if results.get('Q-learning') and results.get('PPO V2'):
        improvement = (results['PPO V2']['avg'] - results['Q-learning']['avg']) / max(results['Q-learning']['avg'], 0.01) * 100
        print(f"PPO V2 ç›¸æ¯” Q-learning: {improvement:+.1f}%")
    
    if results.get('PPO V1') and results.get('PPO V2'):
        improvement = (results['PPO V2']['avg'] - results['PPO V1']['avg']) / max(results['PPO V1']['avg'], 0.01) * 100
        print(f"PPO V2 ç›¸æ¯” PPO V1: {improvement:+.1f}%")
    
    print("\n" + "="*70)
    print("ç‰¹æ€§å°æ¯”")
    print("="*70)
    
    print("\nQ-learning:")
    print("  âœ“ ç°¡å–®æ˜“æ‡‚")
    print("  âœ“ è¨“ç·´å¿«é€Ÿï¼ˆå°æ£‹ç›¤ï¼‰")
    print("  âœ— ç‹€æ…‹ç©ºé–“çˆ†ç‚¸ï¼ˆå¤§æ£‹ç›¤ï¼‰")
    
    print("\nPPO V1:")
    print("  âœ“ æ·±åº¦ç¥ç¶“ç¶²è·¯")
    print("  âœ“ æ“´å±•æ€§å¼·")
    print("  âœ“ 12-d è§€å¯Ÿç©ºé–“")
    print("  âœ— å®¹æ˜“æ’åˆ°è‡ªå·±")
    
    print("\nPPO V2:")
    print("  âœ“ æ¼¸é€²å¼ç¢°æ’æ‡²ç½°")
    print("  âœ“ 16-d è§€å¯Ÿç©ºé–“ (å«èº«é«”æ„ŸçŸ¥)")
    print("  âœ“ å›°å¢ƒåµæ¸¬")
    print("  âœ“ æ›´å¥½çš„é¿éšœèƒ½åŠ›")
    
    print("="*70)


def advanced_mode():
    """é€²éšæ¨¡å¼ï¼šè®“ç”¨æˆ¶é¸æ“‡ç‰¹å®šæ¨¡å‹å’Œæ£‹ç›¤å¤§å°"""
    
    print("\n" + "="*70)
    print("é€²éšæ¨¡å¼ - è‡ªè¨‚é¸æ“‡")
    print("="*70)
    
    # é¡¯ç¤ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
    available_models = list_available_models()
    
    print("\nè«‹é¸æ“‡ AI é¡å‹:")
    print("  1. Q-learning")
    print("  2. PPO V1")
    print("  3. PPO V2 (æ¨è–¦)")
    
    ai_choice = input("\nè«‹è¼¸å…¥é¸æ“‡ (1-3): ").strip()
    
    if ai_choice == '1':
        # Q-learning
        if not available_models['qlearning']:
            print("\næ²’æœ‰å¯ç”¨çš„ Q-learning æ¨¡å‹")
            return
        
        print("\nå¯ç”¨çš„ Q-learning æ¨¡å‹:")
        for i, model in enumerate(available_models['qlearning'], 1):
            print(f"  {i}. {model}")
        
        if len(available_models['qlearning']) == 1:
            model_idx = 0
        else:
            model_choice = input(f"\nè«‹é¸æ“‡æ¨¡å‹ (1-{len(available_models['qlearning'])}): ").strip()
            model_idx = int(model_choice) - 1
        
        model_path = available_models['qlearning'][model_idx]
        board_size = get_user_choice_board_size()
        
        print(f"\nè¼‰å…¥æ¨¡å‹: {model_path}")
        print(f"æ£‹ç›¤å¤§å°: {board_size}x{board_size}")
        
        watch_ai_play(board_size=board_size, model_path=model_path)
    
    elif ai_choice == '2':
        # PPO V1
        if not HAS_PPO:
            print("\néœ€è¦å®‰è£ stable_baselines3")
            return
        
        if not available_models['ppo_v1']:
            print("\næ²’æœ‰å¯ç”¨çš„ PPO V1 æ¨¡å‹")
            print("è«‹å…ˆè¨“ç·´æ¨¡å‹: python snake_ai_ppo.py --mode train")
            return
        
        print("\nå¯ç”¨çš„ PPO V1 æ¨¡å‹:")
        for i, model in enumerate(available_models['ppo_v1'], 1):
            print(f"  {i}. {model}")
        
        if len(available_models['ppo_v1']) == 1:
            model_idx = 0
        else:
            model_choice = input(f"\nè«‹é¸æ“‡æ¨¡å‹ (1-{len(available_models['ppo_v1'])}): ").strip()
            model_idx = int(model_choice) - 1
        
        model_path = available_models['ppo_v1'][model_idx]
        board_size = get_user_choice_board_size()
        
        print(f"\nè¼‰å…¥æ¨¡å‹: {model_path}")
        print(f"æ£‹ç›¤å¤§å°: {board_size}x{board_size}")
        
        watch_ppo_play(version='v1', board_size=board_size, model_path=model_path)
    
    elif ai_choice == '3':
        # PPO V2
        if not HAS_PPO:
            print("\néœ€è¦å®‰è£ stable_baselines3")
            return
        
        if not available_models['ppo_v2']:
            print("\næ²’æœ‰å¯ç”¨çš„ PPO V2 æ¨¡å‹")
            print("è«‹å…ˆè¨“ç·´æ¨¡å‹: python snake_ai_ppo_v2.py --mode train")
            return
        
        print("\nå¯ç”¨çš„ PPO V2 æ¨¡å‹:")
        for i, model in enumerate(available_models['ppo_v2'], 1):
            print(f"  {i}. {model}")
        
        if len(available_models['ppo_v2']) == 1:
            model_idx = 0
        else:
            model_choice = input(f"\nè«‹é¸æ“‡æ¨¡å‹ (1-{len(available_models['ppo_v2'])}): ").strip()
            model_idx = int(model_choice) - 1
        
        model_path = available_models['ppo_v2'][model_idx]
        board_size = get_user_choice_board_size()
        
        print(f"\nè¼‰å…¥æ¨¡å‹: {model_path}")
        print(f"æ£‹ç›¤å¤§å°: {board_size}x{board_size}")
        
        watch_ppo_play(version='v2', board_size=board_size, model_path=model_path)
    
    else:
        print("ç„¡æ•ˆé¸æ“‡")


def run_with_ui_selector():
    """ä½¿ç”¨åœ–å½¢åŒ– UI é¸æ“‡æ¨¡å‹ä¸¦é‹è¡Œæ¼”ç¤º"""
    print("\n" + "="*70)
    print("ğŸ è²ªåƒè›‡ AI æ¼”ç¤ºç¨‹åº - åœ–å½¢åŒ–é¸æ“‡ç•Œé¢")
    print("="*70)
    print("\næ­£åœ¨å•Ÿå‹•æ¨¡å‹é¸æ“‡å™¨...")
    
    # é‹è¡Œé¸æ“‡å™¨
    selector = ModelSelector(width=900, height=700)
    model_type, model_path, board_size = selector.run()
    
    # æª¢æŸ¥æ˜¯å¦å–æ¶ˆ
    if model_type is None:
        print("\nå·²å–æ¶ˆé¸æ“‡")
        return
    
    print(f"\né¸æ“‡çš„é…ç½®:")
    print(f"  æ¨¡å‹é¡å‹: {model_type}")
    print(f"  æ¨¡å‹è·¯å¾‘: {model_path}")
    print(f"  æ£‹ç›¤å¤§å°: {board_size}x{board_size}")
    print("\næ­£åœ¨å•Ÿå‹•éŠæˆ²...")
    
    # æ ¹æ“šæ¨¡å‹é¡å‹é‹è¡Œç›¸æ‡‰çš„æ¼”ç¤º
    if model_type == 'qlearning':
        watch_ai_play(board_size=board_size, model_path=model_path)
    elif model_type == 'ppo_v1':
        watch_ppo_play(version='v1', board_size=board_size, model_path=model_path)
    elif model_type == 'ppo_v2':
        watch_ppo_play(version='v2', board_size=board_size, model_path=model_path)
    elif model_type == 'ppo_v3':
        watch_ppo_play(version='v3', board_size=board_size, model_path=model_path)
    
def main():
    """ä¸»å‡½æ•¸"""
    
    print("\n" + "="*70)
    print("ğŸ è²ªåƒè›‡ AI æ¼”ç¤ºç¨‹åº")
    print("="*70)
    
    # é¡¯ç¤ºå¯ç”¨æ¨¡å‹
    available_models = list_available_models()
    has_qlearning = len(available_models['qlearning']) > 0
    has_ppo_v1 = len(available_models['ppo_v1']) > 0
    has_ppo_v2 = len(available_models['ppo_v2']) > 0
    has_ppo_v3 = len(available_models['ppo_v3']) > 0
    
    print("\nå¯ç”¨çš„ AI æ¨¡å‹:")
    if has_qlearning:
        print(f"  âœ“ Q-learning: {len(available_models['qlearning'])} å€‹æ¨¡å‹")
    else:
        print(f"  âœ— Q-learning: ç„¡å¯ç”¨æ¨¡å‹")
    
    if HAS_PPO:
        if has_ppo_v1:
            print(f"  âœ“ PPO V1: {len(available_models['ppo_v1'])} å€‹æ¨¡å‹")
        else:
            print(f"  âœ— PPO V1: ç„¡å¯ç”¨æ¨¡å‹")
        
        if has_ppo_v2:
            print(f"  âœ“ PPO V2: {len(available_models['ppo_v2'])} å€‹æ¨¡å‹")
        else:
            print(f"  âœ— PPO V2: ç„¡å¯ç”¨æ¨¡å‹")
        
        if has_ppo_v3:
            print(f"  âœ“ PPO V3 (èª²ç¨‹å­¸ç¿’): {len(available_models['ppo_v3'])} å€‹æ¨¡å‹")
        else:
            print(f"  âœ— PPO V3: ç„¡å¯ç”¨æ¨¡å‹")
    else:
        print(f"  âœ— PPO: éœ€è¦å®‰è£ stable_baselines3")
    
    print("\n" + "="*70)
    print("è«‹é¸æ“‡æ¼”ç¤ºæ¨¡å¼:")
    print()
    print("â”â”â” åœ–å½¢åŒ–é¸æ“‡ (æ¨è–¦) ğŸ¨ â”â”â”")
    print("  0. ä½¿ç”¨åœ–å½¢åŒ–ç•Œé¢é¸æ“‡æ¨¡å‹ â­ NEW!")
    print()
    print("â”â”â” Q-learning æ–¹æ³• (å‚³çµ±å¼·åŒ–å­¸ç¿’) â”â”â”")
    print("  1. è§€çœ‹ Q-learning AI éŠæˆ² (å¯é¸æ£‹ç›¤å¤§å°)")
    print("  2. Q-learning è¨“ç·´å‰å¾Œæ¯”è¼ƒ")
    print("  3. Q-learning AI ç­–ç•¥åˆ†æ")
    print()
    
    if HAS_PPO:
        print("â”â”â” PPO æ–¹æ³• (æ·±åº¦å¼·åŒ–å­¸ç¿’) ğŸŒŸ â”â”â”")
        print("  4. è§€çœ‹ PPO V1 AI éŠæˆ² (å¯é¸æ£‹ç›¤å¤§å°)")
        print("  5. è§€çœ‹ PPO V2 AI éŠæˆ² (å¢å¼·ç‰ˆï¼Œæ¨è–¦) â­")
        print("  6. Q-learning vs PPO V1 vs PPO V2 ä¸‰æ–¹æ¯”è¼ƒ")
        print("  7. é¸æ“‡ç‰¹å®šæ¨¡å‹å’Œæ£‹ç›¤å¤§å° (é€²éš)")
    else:
        print("â”â”â” PPO æ–¹æ³• (éœ€è¦å®‰è£ stable_baselines3) â”â”â”")
        print("  å®‰è£æ–¹æ³•: pip install stable-baselines3 torch")
    
    print()
    print("="*70)
    
    try:
        choice = input("\nè«‹è¼¸å…¥é¸æ“‡ (0-7): ").strip()
        
        if choice == '0':
            run_with_ui_selector()
        elif choice == '1':
            watch_ai_play()
        elif choice == '2':
            compare_before_after_training()
        elif choice == '3':
            analyze_ai_strategy()
        elif choice == '4':
            if HAS_PPO:
                watch_ppo_play(version='v1')
            else:
                print("\nè«‹å…ˆå®‰è£ stable_baselines3:")
                print("  pip install stable-baselines3 torch")
        elif choice == '5':
            if HAS_PPO:
                watch_ppo_play(version='v2')
            else:
                print("\nè«‹å…ˆå®‰è£ stable_baselines3:")
                print("  pip install stable-baselines3 torch")
        elif choice == '6':
            if HAS_PPO:
                compare_all_methods()
            else:
                print("\nè«‹å…ˆå®‰è£ stable_baselines3:")
                print("  pip install stable-baselines3 torch")
        elif choice == '7':
            if HAS_PPO:
                advanced_mode()
            else:
                print("\nè«‹å…ˆå®‰è£ stable_baselines3:")
                print("  pip install stable-baselines3 torch")
        else:
            print("ç„¡æ•ˆé¸æ“‡")
            
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·")

if __name__ == "__main__":
    main()